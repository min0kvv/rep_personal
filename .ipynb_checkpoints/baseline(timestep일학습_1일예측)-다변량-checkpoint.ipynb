{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e4a85878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV, RandomizedSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "## keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from keras.optimizers import adam\n",
    "from tensorflow.keras import Sequential,layers, callbacks\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "def create_xset(xset, back_week):\n",
    "    x_data = []\n",
    "    for i in range(0, len(xset)-back_week):\n",
    "        x_data.append(xset[i:i+back_week]) # \n",
    "    return np.array(x_data)\n",
    "\n",
    "def create_yset(st,nd,rd,th, step, start=0): # x:timestep 사용 y:predstep 사용\n",
    "    fin_data = []\n",
    "    for i in range(start, len(st)):\n",
    "        add=[]\n",
    "        add.append(st[i:i+step])\n",
    "        add.append(nd[i:i+step])\n",
    "        add.append(rd[i:i+step])\n",
    "        add.append(th[i:i+step])\n",
    "        fin_data.append(np.array(add))   \n",
    "    return np.array(fin_data)\n",
    "\n",
    "def create_dataset(xset, yset, back_week):\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    for i in range(0, len(xset)-back_week):\n",
    "        x_data.append(xset[i:i+back_week]) # \n",
    "        y_data.append(yset[i+back_week]) #\n",
    "    return np.array(x_data), np.array(y_data)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "sns.set(font=\"Malgun Gothic\", \n",
    "        rc={\"axes.unicode_minus\":False},\n",
    "        style='darkgrid')\n",
    "\n",
    "os.chdir('D:/git/final_dacon/20221130 (1)')\n",
    "origin=pd.read_csv('./total_dataset.csv', encoding='UTF-8', index_col=0)\n",
    "# df=df[5:].reset_index() # 개수 1456 이 8과 16을 약수로 갖기 때문\n",
    "# df.drop(columns=[]\n",
    "df=origin[:1125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "29a7f675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "광진구       334\n",
       "동대문구      334\n",
       "성동구       334\n",
       "중랑구       334\n",
       "gw_sub      0\n",
       "dd_sub      0\n",
       "sd_sub      0\n",
       "gr_sub      0\n",
       "sunday      0\n",
       "mon_1       0\n",
       "mon_2       0\n",
       "mon_3       0\n",
       "mon_4       0\n",
       "mon_5       0\n",
       "mon_6       0\n",
       "mon_7       0\n",
       "mon_8       0\n",
       "mon_9       0\n",
       "mon_10      0\n",
       "mon_11      0\n",
       "mon_12      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b22a93c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['광진구', '동대문구', '성동구', '중랑구', 'gw_sub', 'dd_sub', 'sd_sub', 'gr_sub',\n",
       "       'sunday', 'mon_1', 'mon_2', 'mon_3', 'mon_4', 'mon_5', 'mon_6', 'mon_7',\n",
       "       'mon_8', 'mon_9', 'mon_10', 'mon_11', 'mon_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b25b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "## timestep 설정\n",
    "timestep=2 # 학습하는 일 수: 2의 제곱수 2, 4, 8, 16 가능 \n",
    "predstep=1 # 예측하는 일 수\n",
    "\n",
    "x_cols=['gw_sub', 'dd_sub', 'sd_sub', 'gr_sub',\n",
    "       'sunday', 'mon_1', 'mon_2', 'mon_3', 'mon_4', 'mon_5', 'mon_6', 'mon_7',\n",
    "       'mon_8', 'mon_9', 'mon_10', 'mon_11', 'mon_12']\n",
    "y_cols=['광진구', '동대문구', '성동구', '중랑구']\n",
    "f_num=len(x_cols) # 17개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "12171d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = origin[x_cols] # train, val, test 존재\n",
    "y_data = df[y_cols] # train, val 만 존재\n",
    "\n",
    "scaler_x = RobustScaler()\n",
    "x_scaled=robust_x.fit_transform(x_data)\n",
    "\n",
    "scaler_y = RobustScaler()\n",
    "y_scaled=robust_y.fit_transform(y_data)\n",
    "\n",
    "x_scale = x_scaled.astype('float')[:1125] # 1125부턴 test set\n",
    "y_scale = y_scaled.astype('float')\n",
    "\n",
    "\n",
    "# x_train = x_scale[:900]\n",
    "# x_val = x_scale[900:1125]\n",
    "# x_test = x_scale[1125:]\n",
    "\n",
    "# y_train = y_scale[:900]\n",
    "# y_val = y_scale[900:]\n",
    "\n",
    "type(y_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7205c3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(898, 2, 17) (225, 2, 17) (898, 4) (225, 4)\n"
     ]
    }
   ],
   "source": [
    "x_set, y_set = create_dataset(x_scale, y_scale, timestep)\n",
    "# y_set = np.reshape(y_set,(1452,4,1))\n",
    "\n",
    "# print(x_set.shape, y_set.shape)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_set, y_set, test_size=0.2, shuffle=False)\n",
    "print(x_train.shape,x_val.shape,y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aabd60f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_24 (LSTM)               (None, 2, 128)            74752     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 32)                20608     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 95,492\n",
      "Trainable params: 95,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(timestep, f_num), activation=tf.keras.layers.LeakyReLU(),return_sequences=True))\n",
    "# model.add(LSTM(64, input_shape=(timestep, f_num), activation='relu',return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(32, activation=tf.keras.layers.LeakyReLU()))\n",
    "# model.add(LSTM(32, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(4))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b34ac2ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 898 samples, validate on 225 samples\n",
      "Epoch 1/50\n",
      "898/898 [==============================] - 10s 11ms/sample - loss: 0.4696 - mae: 0.4696 - val_loss: 0.6180 - val_mae: 0.6180\n",
      "Epoch 2/50\n",
      "898/898 [==============================] - 0s 490us/sample - loss: 0.4364 - mae: 0.4364 - val_loss: 0.6250 - val_mae: 0.6250\n",
      "Epoch 3/50\n",
      "898/898 [==============================] - 1s 833us/sample - loss: 0.3437 - mae: 0.3437 - val_loss: 0.5262 - val_mae: 0.5262\n",
      "Epoch 4/50\n",
      "898/898 [==============================] - 1s 845us/sample - loss: 0.3028 - mae: 0.3028 - val_loss: 0.5077 - val_mae: 0.5077\n",
      "Epoch 5/50\n",
      "898/898 [==============================] - 1s 864us/sample - loss: 0.2905 - mae: 0.2905 - val_loss: 0.4902 - val_mae: 0.4902\n",
      "Epoch 6/50\n",
      "898/898 [==============================] - 1s 955us/sample - loss: 0.2841 - mae: 0.2841 - val_loss: 0.4658 - val_mae: 0.4658\n",
      "Epoch 7/50\n",
      "898/898 [==============================] - 1s 968us/sample - loss: 0.2793 - mae: 0.2793 - val_loss: 0.4761 - val_mae: 0.4761\n",
      "Epoch 8/50\n",
      "898/898 [==============================] - 1s 977us/sample - loss: 0.2732 - mae: 0.2732 - val_loss: 0.4621 - val_mae: 0.4621\n",
      "Epoch 9/50\n",
      "898/898 [==============================] - 1s 956us/sample - loss: 0.2723 - mae: 0.2723 - val_loss: 0.4520 - val_mae: 0.4520\n",
      "Epoch 10/50\n",
      "898/898 [==============================] - 1s 962us/sample - loss: 0.2723 - mae: 0.2723 - val_loss: 0.4601 - val_mae: 0.4601\n",
      "Epoch 11/50\n",
      "898/898 [==============================] - 1s 984us/sample - loss: 0.2659 - mae: 0.2659 - val_loss: 0.4444 - val_mae: 0.4444\n",
      "Epoch 12/50\n",
      "898/898 [==============================] - 1s 963us/sample - loss: 0.2644 - mae: 0.2644 - val_loss: 0.4398 - val_mae: 0.4398\n",
      "Epoch 13/50\n",
      "898/898 [==============================] - 1s 970us/sample - loss: 0.2651 - mae: 0.2651 - val_loss: 0.4293 - val_mae: 0.4293\n",
      "Epoch 14/50\n",
      "898/898 [==============================] - 1s 971us/sample - loss: 0.2644 - mae: 0.2644 - val_loss: 0.4529 - val_mae: 0.4529\n",
      "Epoch 15/50\n",
      "898/898 [==============================] - 1s 970us/sample - loss: 0.2645 - mae: 0.2645 - val_loss: 0.4233 - val_mae: 0.4233\n",
      "Epoch 16/50\n",
      "898/898 [==============================] - 1s 964us/sample - loss: 0.2698 - mae: 0.2698 - val_loss: 0.4448 - val_mae: 0.4448\n",
      "Epoch 17/50\n",
      "898/898 [==============================] - 1s 968us/sample - loss: 0.2652 - mae: 0.2652 - val_loss: 0.4298 - val_mae: 0.4298\n",
      "Epoch 18/50\n",
      "898/898 [==============================] - 1s 956us/sample - loss: 0.2568 - mae: 0.2568 - val_loss: 0.4182 - val_mae: 0.4182\n",
      "Epoch 19/50\n",
      "898/898 [==============================] - 1s 1ms/sample - loss: 0.2571 - mae: 0.2571 - val_loss: 0.4309 - val_mae: 0.4309\n",
      "Epoch 20/50\n",
      "898/898 [==============================] - 1s 949us/sample - loss: 0.2539 - mae: 0.2539 - val_loss: 0.4238 - val_mae: 0.4238\n",
      "Epoch 21/50\n",
      "898/898 [==============================] - 1s 957us/sample - loss: 0.2586 - mae: 0.2586 - val_loss: 0.4337 - val_mae: 0.4337\n",
      "Epoch 22/50\n",
      "898/898 [==============================] - 1s 937us/sample - loss: 0.2609 - mae: 0.2609 - val_loss: 0.4308 - val_mae: 0.4308\n",
      "Epoch 23/50\n",
      "898/898 [==============================] - 1s 961us/sample - loss: 0.2515 - mae: 0.2515 - val_loss: 0.4456 - val_mae: 0.4456\n",
      "Epoch 24/50\n",
      "898/898 [==============================] - 1s 954us/sample - loss: 0.2555 - mae: 0.2555 - val_loss: 0.4283 - val_mae: 0.4283\n",
      "Epoch 25/50\n",
      "898/898 [==============================] - 1s 940us/sample - loss: 0.2556 - mae: 0.2556 - val_loss: 0.4258 - val_mae: 0.4258\n",
      "Epoch 26/50\n",
      "898/898 [==============================] - 1s 944us/sample - loss: 0.2521 - mae: 0.2521 - val_loss: 0.4239 - val_mae: 0.4239\n",
      "Epoch 27/50\n",
      "898/898 [==============================] - 1s 960us/sample - loss: 0.2540 - mae: 0.2540 - val_loss: 0.4210 - val_mae: 0.4210\n",
      "Epoch 28/50\n",
      "898/898 [==============================] - 1s 976us/sample - loss: 0.2470 - mae: 0.2470 - val_loss: 0.4334 - val_mae: 0.4334\n",
      "Epoch 29/50\n",
      "898/898 [==============================] - 1s 945us/sample - loss: 0.2511 - mae: 0.2511 - val_loss: 0.4366 - val_mae: 0.4366\n",
      "Epoch 30/50\n",
      "898/898 [==============================] - 1s 951us/sample - loss: 0.2492 - mae: 0.2492 - val_loss: 0.4541 - val_mae: 0.4541\n",
      "Epoch 31/50\n",
      "898/898 [==============================] - 1s 970us/sample - loss: 0.2536 - mae: 0.2536 - val_loss: 0.4169 - val_mae: 0.4169\n",
      "Epoch 32/50\n",
      "898/898 [==============================] - 1s 1ms/sample - loss: 0.2468 - mae: 0.2468 - val_loss: 0.4409 - val_mae: 0.4409\n",
      "Epoch 33/50\n",
      "898/898 [==============================] - 1s 978us/sample - loss: 0.2450 - mae: 0.2450 - val_loss: 0.4538 - val_mae: 0.4538\n",
      "Epoch 34/50\n",
      "898/898 [==============================] - 1s 946us/sample - loss: 0.2482 - mae: 0.2482 - val_loss: 0.4178 - val_mae: 0.4178\n",
      "Epoch 35/50\n",
      "898/898 [==============================] - 0s 531us/sample - loss: 0.2431 - mae: 0.2431 - val_loss: 0.4276 - val_mae: 0.4276\n",
      "Epoch 36/50\n",
      "898/898 [==============================] - 1s 720us/sample - loss: 0.2464 - mae: 0.2464 - val_loss: 0.4242 - val_mae: 0.4242\n",
      "Epoch 37/50\n",
      "898/898 [==============================] - 1s 919us/sample - loss: 0.2402 - mae: 0.2402 - val_loss: 0.4419 - val_mae: 0.4419\n",
      "Epoch 38/50\n",
      "898/898 [==============================] - 1s 783us/sample - loss: 0.2418 - mae: 0.2418 - val_loss: 0.4294 - val_mae: 0.4294\n",
      "Epoch 39/50\n",
      "898/898 [==============================] - 1s 890us/sample - loss: 0.2413 - mae: 0.2413 - val_loss: 0.4367 - val_mae: 0.4367\n",
      "Epoch 40/50\n",
      "898/898 [==============================] - 1s 988us/sample - loss: 0.2424 - mae: 0.2424 - val_loss: 0.4279 - val_mae: 0.4279\n",
      "Epoch 41/50\n",
      "898/898 [==============================] - 1s 988us/sample - loss: 0.2405 - mae: 0.2405 - val_loss: 0.4427 - val_mae: 0.4427\n",
      "Epoch 42/50\n",
      "898/898 [==============================] - 1s 967us/sample - loss: 0.2398 - mae: 0.2398 - val_loss: 0.4519 - val_mae: 0.4519\n",
      "Epoch 43/50\n",
      "898/898 [==============================] - 1s 967us/sample - loss: 0.2392 - mae: 0.2392 - val_loss: 0.4308 - val_mae: 0.4308\n",
      "Epoch 44/50\n",
      "898/898 [==============================] - 1s 994us/sample - loss: 0.2409 - mae: 0.2409 - val_loss: 0.4463 - val_mae: 0.4463\n",
      "Epoch 45/50\n",
      "898/898 [==============================] - 1s 919us/sample - loss: 0.2414 - mae: 0.2414 - val_loss: 0.4276 - val_mae: 0.4276\n",
      "Epoch 46/50\n",
      "898/898 [==============================] - 1s 964us/sample - loss: 0.2394 - mae: 0.2394 - val_loss: 0.4434 - val_mae: 0.4434\n",
      "Epoch 47/50\n",
      "898/898 [==============================] - 1s 927us/sample - loss: 0.2384 - mae: 0.2384 - val_loss: 0.4539 - val_mae: 0.4539\n",
      "Epoch 48/50\n",
      "898/898 [==============================] - 1s 1ms/sample - loss: 0.2402 - mae: 0.2402 - val_loss: 0.4319 - val_mae: 0.4319\n",
      "Epoch 49/50\n",
      "898/898 [==============================] - 1s 963us/sample - loss: 0.2374 - mae: 0.2374 - val_loss: 0.4303 - val_mae: 0.4303\n",
      "Epoch 50/50\n",
      "898/898 [==============================] - 1s 990us/sample - loss: 0.2434 - mae: 0.2434 - val_loss: 0.4347 - val_mae: 0.4347\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mae', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "epoch=50; batch=32; verbose=1;\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "            epochs=epoch,\n",
    "            batch_size=batch, \n",
    "            verbose=verbose,\n",
    "            validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aff65149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val MAE: 2.0630527469656195\n",
      "train MAE 1.0469565765865663\n"
     ]
    }
   ],
   "source": [
    "trainPredict = model.predict(x_train) # 예측값\n",
    "valPredict = model.predict(x_val) # 예측값\n",
    "\n",
    "val_rescale = robust_y.inverse_transform(valPredict)\n",
    "train_rescale = robust_y.inverse_transform(trainPredict)\n",
    "\n",
    "val_act=robust_y.inverse_transform(y_val)\n",
    "train_act=robust_y.inverse_transform(y_train)\n",
    "\n",
    "print('val MAE:',mean_absolute_error(val_act,val_rescale))\n",
    "print('train MAE',mean_absolute_error(train_act,train_rescale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9b6cf795",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_value = x_scaled.astype('float')[1123:]\n",
    "x_test = create_xset(x_test_value, timestep)\n",
    "testPredict = model.predict(x_test)\n",
    "test_rescale = robust_y.inverse_transform(testPredict)\n",
    "\n",
    "gw_list = []\n",
    "dd_list = []\n",
    "sd_list = []\n",
    "gr_list = []\n",
    "for i in range(len(test_rescale)):\n",
    "    gw_list.append(test_rescale[i][0])\n",
    "    dd_list.append(test_rescale[i][1])\n",
    "    sd_list.append(test_rescale[i][2])\n",
    "    gr_list.append(test_rescale[i][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "19dabbcf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sub=pd.read_csv('./sample_submission.csv', encoding='UTF-8', index_col=0)\n",
    "submit = pd.DataFrame({ '일시':sub.index, '광진구':gw_list, '동대문구':dd_list, '성동구':sd_list, '중랑구':gr_list})\n",
    "submit.head()\n",
    "\n",
    "submit.to_csv('./submit_1201.csv', encoding='UTF-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be734cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lstm randomsearchcv 하기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.0",
   "language": "python",
   "name": "tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
